{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Work 3. Логистическая регрессия. Log Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения домашнего задания будем использовать файл Lesson_3_extended.ipynb из материалов к уроку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([ [   1,    1,  500,    1],\n",
    "               [   1,    1,  700,    1],\n",
    "               [   1,    2,  750,    2],\n",
    "               [   1,    5,  600,    1],\n",
    "               [   1,    3, 1450,    2],\n",
    "               [   1,    0,  800,    1],\n",
    "               [   1,    5, 1500,    3],\n",
    "               [   1,   10, 2000,    3],\n",
    "               [   1,    1,  450,    1],\n",
    "               [   1,    2, 1000,    2]], dtype=np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scale(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = X.copy()\n",
    "X_st[:, 2] = standard_scale(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, eta=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[1])\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        z = np.dot(X, W)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        \n",
    "        dQ = 1/n * X.T @ (y_pred - y)\n",
    "        W -= eta * dQ\n",
    "#         if i % (iterations / 10) == 0:\n",
    "#             print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1*. Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи, применим функцию **np.clip**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "    err = np.mean(- y * np.log(np.clip(y_pred, a_min=0.00001, a_max=1)) - \\\n",
    "                  (1.0 - y) * np.log(np.clip(1.0 - y_pred, a_min=0.00001, a_max=1)))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(calc_logloss(np.array([0, 1]), np.array([0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2. Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучшая ошибка 0.2825319832255081 с параметрами {'eta': 0.004, 'n_iter': 100000}\n"
     ]
    }
   ],
   "source": [
    "iterations_list = [1000, 5000, 10000, 15000, 20000, 100000]\n",
    "eta_list = [1e-3, 1e-4, 1e-5, 0.002, 0.003, 0.004]\n",
    "\n",
    "best_error = np.inf\n",
    "best_params = {}\n",
    "\n",
    "for i in iterations_list:\n",
    "    for j in eta_list:\n",
    "        np.random.seed(42)\n",
    "        W = np.random.randn(X_st.shape[1])\n",
    "        n = X_st.shape[0]\n",
    "    \n",
    "        for i in range(i+1):\n",
    "            z = np.dot(X_st, W)\n",
    "            y_pred = sigmoid(z)\n",
    "            err = calc_logloss(y, y_pred)\n",
    "        \n",
    "            dQ = 1/n * X_st.T @ (y_pred - y)\n",
    "            W -= j * dQ\n",
    "        if err < best_error:\n",
    "            best_error = err\n",
    "            best_params = {\n",
    "                    'eta': j,\n",
    "                    'n_iter': i\n",
    "            }\n",
    "                    \n",
    "print(f'\\nЛучшая ошибка {best_error} с параметрами {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3. Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.58491989, -1.08568691, -1.09077503,  5.8979015 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations = 100000, eta=0.004)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(x, w):\n",
    "    z = np.dot(x, w) # значения функции линейной регрессии\n",
    "    y_pred_proba = sigmoid(z) # находим предсказанные вероятности\n",
    "    return list(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3308831702513757, 0.23974225517352413, 0.9719590174515729, 0.005107671641483346, 0.7079214562546317, 0.42718244211706785, 0.9890061348157567, 0.11366687123949587, 0.35624067525002673, 0.9518126561185714]\n"
     ]
    }
   ],
   "source": [
    "print(calc_pred_proba(X_st, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 4. Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(x, w):\n",
    "    z = np.dot(x, w) # значения функции линейной регрессии\n",
    "    y_pred_proba = sigmoid(z) # находим предсказанные вероятности\n",
    "    y_pred = [1 if y > 0.5 else 0 for y in y_pred_proba] # переводим в 0 и 1\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 0 1 0 0 1]\n",
      "[0 0 1 0 1 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(calc_pred(X_st, W))\n",
    "print(y.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 5*. Реализуйте функции для подсчета Accuracy, матрицы ошибок, точности и полноты, а также F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = calc_pred(X_st, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**  \n",
    "(доля правильных ответов):\n",
    "\n",
    "$$accuracy(a,x) = \\frac{1}{l} \\sum^{l}_{i=1}[a(x_{i})=y_{i}].$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_accuracy(y_pred, y):\n",
    "    acc = np.sum((y_pred == y)+0) / len(y)\n",
    "    return str(round(acc*100, 1)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90.0%'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_accuracy(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Матрица ошибок**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  <empty>   | $$y = +1$$ | $$y = -1$$ |\n",
    "--- | --- | ---\n",
    "| __$$a(x) = +1$$__  |  True Positive TP    |  False Positive  FP   |\n",
    "| __$$a(x) = -1$$__ |   False Negative FN    |   True Negative TN   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_confusion_matrix(y_pred, y):\n",
    "    err_matrix = np.zeros((2, 2))\n",
    "    for i in range(len(y)):\n",
    "        if y_pred[i] == 1 and y[i] == 1:\n",
    "            err_matrix[0][0] += 1\n",
    "        elif y_pred[i] == 1 and y[i] != 1:\n",
    "            err_matrix[0][1] += 1\n",
    "        elif y_pred[i] == 0 and y[i] == 0:\n",
    "            err_matrix[1][1] += 1\n",
    "        else:\n",
    "            err_matrix[1][0] += 1\n",
    "    return err_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 0.]\n",
      " [1. 5.]]\n"
     ]
    }
   ],
   "source": [
    "print(score_confusion_matrix(y_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Точность**  \n",
    "Точность (precision) представляет из себя долю истинных срабатываний от общего количества срабатываний. Она показывает, насколько можно доверять алгоритму классификации в случае срабатывания\n",
    "\n",
    "$$precision(a, X) = \\frac{TP}{TP+FP}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(y_pred, y):    \n",
    "    TP = sum([1 if i[0] == i[1] == 1 else 0 for i in zip(y, y_pred)])\n",
    "    FP = sum([1 if i[0] == 1 and i[1] == 0 else 0 for i in zip(y, y_pred)])\n",
    "    precision = TP / (TP + FP)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Полнота**  \n",
    "Полнота (recall) считается как доля объектов, истинно относящихся к классу \"+1\", которые алгоритм отнес к этому классу\n",
    "\n",
    "$$recall(a, X) = \\frac{TP}{TP+FN},$$\n",
    "\n",
    "здесь $TP+FN$ как раз будут вместе составлять весь список объектов класса \"+1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(y_pred, y):\n",
    "    TP = sum([1 if i[0] == i[1] == 1 else 0 for i in zip(y, y_pred)])\n",
    "    TP_FN = sum(y == 1)\n",
    "    recall = TP / TP_FN\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 score**  \n",
    "F-мера представляет собой среднее гармоническое между точностью и полнотой\n",
    "\n",
    "$$F = \\frac{2 \\cdot precision \\cdot recall }{ presision + recall}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(y_pred, y):\n",
    "    TP = sum([1 if i[0] == i[1] == 1 else 0 for i in zip(y, y_pred)])\n",
    "    FP = sum([1 if i[0] == 1 and i[1] == 0 else 0 for i in zip(y, y_pred)])\n",
    "    TP_FN = sum(y == 1)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / TP_FN\n",
    "    F1_score = (2 * precision * recall) / (precision + recall)\n",
    "    return F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8000000000000002"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 6. Могла ли модель переобучиться? Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ**  \n",
    "Модель могла переобучиться, так как в датасете слишком мало наблюдений."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
